# LAL
**NOTE:** This repository was originally forked from [this repository](https://github.com/ksenia-konyushkova/LAL); the original README has been kept below. [Peter Potaptchik](https://github.com/PeterPotaptchik), [Vaskar Nath](https://github.com/VaskarNath), and I (Lukas Willsie) are investigating the potential usage of the pNML ([Koby Bibas, Meir Feder, Tal Hassner, 'Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection', 2021](https://arxiv.org/abs/2110.09246)) and ACNML ([Aurick Zhou, Sergey Levine, 'Amortized Conditional Normalized Maximum Likelihood: Reliable Out of Distribution Uncertainty Estimation', 2020](https://arxiv.org/abs/2011.02696)) distributions as uncertainty metrics for active learning, as part of a group project for a course in deep neural networks. We discovered the original repository during the course of our research and chose to use it as a jumping-off point for running our own active learning experiments.

Code for paper Ksenia Konyushkova, Raphael Sznitman, Pascal Fua 'Learning Active Learning from Data', NIPS 2017

This code can be run with Jupyter notebook 'AL experiments'. You will need the following packages: numpy, sklearn, matplotlib, scipy, time, scipy, math, pickle. 'AL experiment' guides you through the nain steps. It uses classed from folder./Classes, data for experiments is stored in ./data, data for learning a strategy is stored in ./lal datasets and the results are written into ./exp. Class ActiveLearner implements methods Random, Uncertainty Sampling and LAL. For more details refer to the paper and comments in the code.
